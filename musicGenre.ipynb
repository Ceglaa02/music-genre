{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n",
    "!pip install sklearn\n",
    "!pip install librosa\n",
    "!pip install IPython\n",
    "!pip install warnings\n",
    "!pip install os"
   ],
   "id": "971db067db2f19a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (0.62.1)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from numba>=0.51.0->librosa) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pooch>=1.1->librosa) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.10.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from standard-aifc->librosa) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from standard-aifc->librosa) (0.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (9.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from IPython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jedi>=0.16->IPython) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from stack_data->IPython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from stack_data->IPython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\jcple\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from stack_data->IPython) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement warnings (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for warnings\n",
      "ERROR: Could not find a version that satisfies the requirement os (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for os\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:04:27.005730Z",
     "start_time": "2025-11-23T18:04:27.001994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple"
   ],
   "id": "445852dd3e79899a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:04:27.034274Z",
     "start_time": "2025-11-23T18:04:27.024507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zdefiniujemy wszystkie cechy, które będziemy obliczać\n",
    "FEATURE_KEYS: List[str] = [\n",
    "    'tempo',\n",
    "    'mean_zcr',\n",
    "    'mean_rms',\n",
    "    'mean_spectral_centroid',\n",
    "    'mean_spectral_bandwidth',\n",
    "    'mean_spectral_rolloff',\n",
    "] + [f'mfcc_{i}' for i in range(1, 21)] # Dodajemy 20 współczynników MFCC\n",
    "\n",
    "def extract_features(file_path: str, n_mfcc: int = 20) -> Dict[str, float] | None:\n",
    "    \"\"\"Ekstrahuje rozszerzony zestaw cech z pliku audio.\"\"\"\n",
    "    try:\n",
    "        # 1. Ładowanie pliku\n",
    "        y, sr = librosa.load(file_path, mono=True, duration=30)\n",
    "    except Exception as e:\n",
    "        # print(f\"Nie można załadować pliku {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Obliczenia cech\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "    # Agregacja średnich dla cech w dziedzinie czasu/widma\n",
    "    zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
    "    rms = librosa.feature.rms(y=y).mean()\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "    bw = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
    "    roll = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
    "\n",
    "    # MFCC\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    features = {\n",
    "        'tempo': tempo,\n",
    "        'mean_zcr': zcr,\n",
    "        'mean_rms': rms,\n",
    "        'mean_spectral_centroid': cent,\n",
    "        'mean_spectral_bandwidth': bw,\n",
    "        'mean_spectral_rolloff': roll\n",
    "    }\n",
    "\n",
    "    # Dodanie 20 współczynników MFCC\n",
    "    for i in range(n_mfcc):\n",
    "        features[f'mfcc_{i+1}'] = mfccs[i].mean()\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_all_stats(data_path: str, genres: List[str]) -> Tuple[pd.DataFrame, Dict[str, Dict[str, float]], Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Przetwarza cały dataset, oblicza statystyki globalne i wektory idealne gatunków.\n",
    "    \"\"\"\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    # A. Ekstrakcja wszystkich cech i zbieranie danych\n",
    "    print(\"Rozpoczynam ekstrakcję cech z całego datasetu (może zająć kilka minut)...\")\n",
    "    for genre in genres:\n",
    "        genre_path = os.path.join(data_path, genre)\n",
    "        if not os.path.isdir(genre_path):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(genre_path):\n",
    "            if filename.endswith('.au') or filename.endswith('.wav'):\n",
    "                file_path = os.path.join(genre_path, filename)\n",
    "                features = extract_features(file_path)\n",
    "\n",
    "                if features:\n",
    "                    features['genre'] = genre\n",
    "                    all_data.append(features)\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    print(f\"Ekstrakcja zakończona. Przetworzono {len(df)} utworów.\")\n",
    "\n",
    "    # B. Obliczanie statystyk globalnych (do normalizacji)\n",
    "    global_mean = df[FEATURE_KEYS].mean()\n",
    "    global_std = df[FEATURE_KEYS].std()\n",
    "\n",
    "    global_stats = {\n",
    "        key: {'mu': global_mean[key], 'sigma': global_std[key]}\n",
    "        for key in FEATURE_KEYS\n",
    "    }\n",
    "\n",
    "    # C. Obliczanie Wektorów Idealnych Gatunków (średnia dla każdego gatunku)\n",
    "    # Wektory te będą użyte jako referencyjne \"cele\" dla klasyfikacji dystansowej.\n",
    "    genre_profiles_raw = df.groupby('genre')[FEATURE_KEYS].mean()\n",
    "\n",
    "    # D. Normalizacja Wektorów Idealnych na Z-Score (względem statystyk globalnych)\n",
    "    target_profiles: Dict[str, np.ndarray] = {}\n",
    "    for genre in genre_profiles_raw.index:\n",
    "        raw_vector = genre_profiles_raw.loc[genre]\n",
    "        normalized_vector = []\n",
    "        for key in FEATURE_KEYS:\n",
    "            mu = global_stats[key]['mu']\n",
    "            sigma = global_stats[key]['sigma']\n",
    "            # Wzór Z-Score: (X - mu) / sigma\n",
    "            normalized_value = (raw_vector[key] - mu) / sigma\n",
    "            normalized_vector.append(normalized_value)\n",
    "\n",
    "        target_profiles[genre] = np.array(normalized_vector)\n",
    "\n",
    "    return df, global_stats, target_profiles"
   ],
   "id": "90d196d1b57a10fd",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:04:27.049003Z",
     "start_time": "2025-11-23T18:04:27.043899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Te funkcje muszą przyjmować słowniki statystyk i profili jako argumenty!\n",
    "\n",
    "def normalize_features(features: Dict[str, float], stats: Dict[str, Dict[str, float]]) -> np.ndarray:\n",
    "    \"\"\"Normalizuje cechy na Z-Score używając dynamicznie obliczonych statystyk.\"\"\"\n",
    "    normalized_values = []\n",
    "    for key in FEATURE_KEYS:\n",
    "        value = features[key]\n",
    "        mu = stats[key]['mu']\n",
    "        sigma = stats[key]['sigma']\n",
    "        # Wzór Z-Score: (X - mu) / sigma\n",
    "        normalized_values.append((value - mu) / sigma)\n",
    "\n",
    "    return np.array(normalized_values)\n",
    "\n",
    "\n",
    "def classify_by_distance(input_features: Dict[str, float], stats: Dict[str, Dict[str, float]], profiles: Dict[str, np.ndarray]) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Klasyfikuje utwór, obliczając najmniejszą odległość Euklidesową (obliczeniowo).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Normalizacja cech wejściowych\n",
    "    input_vector = normalize_features(input_features, stats)\n",
    "\n",
    "    distances = {}\n",
    "\n",
    "    # 2. Obliczanie odległości\n",
    "    for genre, target_vector in profiles.items():\n",
    "        # Obliczenie Odległości Euklidesowej (norma wektora różnicy)\n",
    "        distance = np.linalg.norm(input_vector - target_vector)\n",
    "        distances[genre] = distance\n",
    "\n",
    "    # 3. Wybór gatunku o najmniejszej odległości\n",
    "    predicted_genre = min(distances, key=distances.get)\n",
    "    min_distance = distances[predicted_genre]\n",
    "\n",
    "    return predicted_genre, min_distance"
   ],
   "id": "187ea9dffacb4b1d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:09:16.937780Z",
     "start_time": "2025-11-23T18:04:27.063927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- KONFIGURACJA I URUCHOMIENIE ---\n",
    "\n",
    "# !!! WAŻNE: ZMIEŃ TĘ ŚCIEŻKĘ NA WŁAŚCIWĄ !!!\n",
    "GTZAN_DATA_PATH = './lib/gtzan-dataset-music-genre-classification/Data/genres_original'\n",
    "# Dostępne gatunki w GTZAN\n",
    "ALL_GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "# 1. FAZA TRENINGOWA (Obliczenie Statystyk i Profili)\n",
    "# W tej fazie Python sam liczy wszystkie stałe.\n",
    "try:\n",
    "    _, global_stats, target_profiles = calculate_all_stats(GTZAN_DATA_PATH, ALL_GENRES)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n[BŁĄD] Upewnij się, że ścieżka GTZAN_DATA_PATH jest poprawna i zawiera folder 'genres_original' z podfolderami gatunków.\")\n",
    "    exit()\n",
    "\n",
    "# Weryfikacja: Zobaczmy, jak wygląda znormalizowany profil Jazzu (obliczony!)\n",
    "print(\"\\n--- Obliczone Wektory Idealne (Fragment) ---\")\n",
    "print(f\"Ilość cech użytych w obliczeniach: {len(FEATURE_KEYS)}\")\n",
    "print(f\"Profil 'Jazz' (pierwsze 5 znormalizowanych cech):\\n{target_profiles['jazz'][:5]}\")\n",
    "print(f\"Profil 'Metal' (pierwsze 5 znormalizowanych cech):\\n{target_profiles['metal'][:5]}\")\n",
    "print(\"-------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# 2. FAZA TESTOWA (Klasyfikacja Utworów)\n",
    "\n",
    "test_results = []\n",
    "test_genres = ['jazz', 'metal', 'classical'] # Testujemy tylko wybrane dla przejrzystości\n",
    "\n",
    "print(\"Rozpoczynam test klasyfikacji...\")\n",
    "for genre in test_genres:\n",
    "    genre_path = os.path.join(GTZAN_DATA_PATH, genre)\n",
    "\n",
    "    # Testujemy tylko kilka pierwszych plików dla każdego gatunku\n",
    "    for i, filename in enumerate(os.listdir(genre_path)):\n",
    "        if i >= 5: # Ogranicz do 5 plików na gatunek\n",
    "            break\n",
    "\n",
    "        if filename.endswith('.au') or filename.endswith('.wav'):\n",
    "            file_path = os.path.join(genre_path, filename)\n",
    "\n",
    "            # A. Ekstrakcja cech z utworu testowego\n",
    "            features = extract_features(file_path)\n",
    "            if features is None:\n",
    "                continue\n",
    "\n",
    "            # B. Klasyfikacja na podstawie obliczeń dystansowych\n",
    "            predicted_genre, distance = classify_by_distance(features, global_stats, target_profiles)\n",
    "\n",
    "            test_results.append({\n",
    "                'true_genre': genre,\n",
    "                'predicted_genre': predicted_genre,\n",
    "                'distance': distance\n",
    "            })\n",
    "\n",
    "            print(f\"[{genre:10}] -> {predicted_genre:10} | Odległość: {distance:.2f}\")\n",
    "\n",
    "# Podsumowanie\n",
    "test_df = pd.DataFrame(test_results)\n",
    "test_accuracy = (test_df['true_genre'] == test_df['predicted_genre']).mean()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Skuteczność testu ({len(test_df)} plików): {test_accuracy*100:.2f}%\")\n",
    "print(\"=\"*50)"
   ],
   "id": "6e260474cce72209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam ekstrakcję cech z całego datasetu (może zająć kilka minut)...\n",
      "Ekstrakcja zakończona. Przetworzono 999 utworów.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert [array([119263.1622445])] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# 1. FAZA TRENINGOWA (Obliczenie Statystyk i Profili)\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# W tej fazie Python sam liczy wszystkie stałe.\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m     _, global_stats, target_profiles = \u001B[43mcalculate_all_stats\u001B[49m\u001B[43m(\u001B[49m\u001B[43mGTZAN_DATA_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mALL_GENRES\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n\u001B[32m     14\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m[BŁĄD] Upewnij się, że ścieżka GTZAN_DATA_PATH jest poprawna i zawiera folder \u001B[39m\u001B[33m'\u001B[39m\u001B[33mgenres_original\u001B[39m\u001B[33m'\u001B[39m\u001B[33m z podfolderami gatunków.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 76\u001B[39m, in \u001B[36mcalculate_all_stats\u001B[39m\u001B[34m(data_path, genres)\u001B[39m\n\u001B[32m     73\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mEkstrakcja zakończona. Przetworzono \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m utworów.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     75\u001B[39m \u001B[38;5;66;03m# B. Obliczanie statystyk globalnych (do normalizacji)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m76\u001B[39m global_mean = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mFEATURE_KEYS\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     77\u001B[39m global_std = df[FEATURE_KEYS].std()\n\u001B[32m     79\u001B[39m global_stats = {\n\u001B[32m     80\u001B[39m     key: {\u001B[33m'\u001B[39m\u001B[33mmu\u001B[39m\u001B[33m'\u001B[39m: global_mean[key], \u001B[33m'\u001B[39m\u001B[33msigma\u001B[39m\u001B[33m'\u001B[39m: global_std[key]}\n\u001B[32m     81\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m FEATURE_KEYS\n\u001B[32m     82\u001B[39m }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:11720\u001B[39m, in \u001B[36mDataFrame.mean\u001B[39m\u001B[34m(self, axis, skipna, numeric_only, **kwargs)\u001B[39m\n\u001B[32m  11712\u001B[39m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[33m\"\u001B[39m\u001B[33mmean\u001B[39m\u001B[33m\"\u001B[39m, ndim=\u001B[32m2\u001B[39m))\n\u001B[32m  11713\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmean\u001B[39m(\n\u001B[32m  11714\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m  11718\u001B[39m     **kwargs,\n\u001B[32m  11719\u001B[39m ):\n\u001B[32m> \u001B[39m\u001B[32m11720\u001B[39m     result = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m  11721\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, Series):\n\u001B[32m  11722\u001B[39m         result = result.__finalize__(\u001B[38;5;28mself\u001B[39m, method=\u001B[33m\"\u001B[39m\u001B[33mmean\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:12485\u001B[39m, in \u001B[36mNDFrame.mean\u001B[39m\u001B[34m(self, axis, skipna, numeric_only, **kwargs)\u001B[39m\n\u001B[32m  12478\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmean\u001B[39m(\n\u001B[32m  12479\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m  12480\u001B[39m     axis: Axis | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[32m0\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m  12483\u001B[39m     **kwargs,\n\u001B[32m  12484\u001B[39m ) -> Series | \u001B[38;5;28mfloat\u001B[39m:\n\u001B[32m> \u001B[39m\u001B[32m12485\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stat_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m  12486\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmean\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnanops\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnanmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m  12487\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:12442\u001B[39m, in \u001B[36mNDFrame._stat_function\u001B[39m\u001B[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[39m\n\u001B[32m  12438\u001B[39m nv.validate_func(name, (), kwargs)\n\u001B[32m  12440\u001B[39m validate_bool_kwarg(skipna, \u001B[33m\"\u001B[39m\u001B[33mskipna\u001B[39m\u001B[33m\"\u001B[39m, none_allowed=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m> \u001B[39m\u001B[32m12442\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_reduce\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m  12443\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnumeric_only\u001B[49m\n\u001B[32m  12444\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:11589\u001B[39m, in \u001B[36mDataFrame._reduce\u001B[39m\u001B[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[39m\n\u001B[32m  11585\u001B[39m     df = df.T\n\u001B[32m  11587\u001B[39m \u001B[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001B[39;00m\n\u001B[32m  11588\u001B[39m \u001B[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001B[39;00m\n\u001B[32m> \u001B[39m\u001B[32m11589\u001B[39m res = \u001B[43mdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_mgr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblk_func\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m  11590\u001B[39m out = df._constructor_from_mgr(res, axes=res.axes).iloc[\u001B[32m0\u001B[39m]\n\u001B[32m  11591\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m out_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m out.dtype != \u001B[33m\"\u001B[39m\u001B[33mboolean\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1519\u001B[39m, in \u001B[36mBlockManager.reduce\u001B[39m\u001B[34m(self, func)\u001B[39m\n\u001B[32m   1517\u001B[39m res_blocks: \u001B[38;5;28mlist\u001B[39m[Block] = []\n\u001B[32m   1518\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.blocks:\n\u001B[32m-> \u001B[39m\u001B[32m1519\u001B[39m     nbs = \u001B[43mblk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1520\u001B[39m     res_blocks.extend(nbs)\n\u001B[32m   1522\u001B[39m index = Index([\u001B[38;5;28;01mNone\u001B[39;00m])  \u001B[38;5;66;03m# placeholder\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:406\u001B[39m, in \u001B[36mBlock.reduce\u001B[39m\u001B[34m(self, func)\u001B[39m\n\u001B[32m    400\u001B[39m \u001B[38;5;129m@final\u001B[39m\n\u001B[32m    401\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mreduce\u001B[39m(\u001B[38;5;28mself\u001B[39m, func) -> \u001B[38;5;28mlist\u001B[39m[Block]:\n\u001B[32m    402\u001B[39m     \u001B[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001B[39;00m\n\u001B[32m    403\u001B[39m     \u001B[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001B[39;00m\n\u001B[32m    404\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ndim == \u001B[32m2\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m406\u001B[39m     result = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    408\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.values.ndim == \u001B[32m1\u001B[39m:\n\u001B[32m    409\u001B[39m         res_values = result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:11508\u001B[39m, in \u001B[36mDataFrame._reduce.<locals>.blk_func\u001B[39m\u001B[34m(values, axis)\u001B[39m\n\u001B[32m  11506\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m np.array([result])\n\u001B[32m  11507\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m> \u001B[39m\u001B[32m11508\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[39m, in \u001B[36mbottleneck_switch.__call__.<locals>.f\u001B[39m\u001B[34m(values, axis, skipna, **kwds)\u001B[39m\n\u001B[32m    145\u001B[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001B[32m    146\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m     result = \u001B[43malt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001B[39m, in \u001B[36m_datetimelike_compat.<locals>.new_func\u001B[39m\u001B[34m(values, axis, skipna, mask, **kwargs)\u001B[39m\n\u001B[32m    401\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m datetimelike \u001B[38;5;129;01mand\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    402\u001B[39m     mask = isna(values)\n\u001B[32m--> \u001B[39m\u001B[32m404\u001B[39m result = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n\u001B[32m    407\u001B[39m     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001B[39m, in \u001B[36mnanmean\u001B[39m\u001B[34m(values, axis, skipna, mask)\u001B[39m\n\u001B[32m    718\u001B[39m count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n\u001B[32m    719\u001B[39m the_sum = values.sum(axis, dtype=dtype_sum)\n\u001B[32m--> \u001B[39m\u001B[32m720\u001B[39m the_sum = \u001B[43m_ensure_numeric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthe_sum\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    722\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(the_sum, \u001B[33m\"\u001B[39m\u001B[33mndim\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m    723\u001B[39m     count = cast(np.ndarray, count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\nanops.py:1686\u001B[39m, in \u001B[36m_ensure_numeric\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m   1683\u001B[39m inferred = lib.infer_dtype(x)\n\u001B[32m   1684\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m inferred \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m\"\u001B[39m\u001B[33mstring\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmixed\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m   1685\u001B[39m     \u001B[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1686\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCould not convert \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m to numeric\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1688\u001B[39m     x = x.astype(np.complex128)\n",
      "\u001B[31mTypeError\u001B[39m: Could not convert [array([119263.1622445])] to numeric"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
